{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19523,"status":"ok","timestamp":1686980972218,"user":{"displayName":"ANKEM HEMA SRIKAR / 학생 / 항공우주공학과 ­","userId":"08215093842889631142"},"user_tz":-540},"id":"M00vAJvZMKSw","outputId":"7d99d233-5c75-48c9-9e0b-b0248aab3902"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1686980972219,"user":{"displayName":"ANKEM HEMA SRIKAR / 학생 / 항공우주공학과 ­","userId":"08215093842889631142"},"user_tz":-540},"id":"kWKN9KqFiIDF","outputId":"42e0ce07-8a01-4b42-c6af-ec2bb67b715a"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["# chage path as you want\n","%cd /content/drive/MyDrive/Colab Notebooks"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":519,"status":"ok","timestamp":1686980972733,"user":{"displayName":"ANKEM HEMA SRIKAR / 학생 / 항공우주공학과 ­","userId":"08215093842889631142"},"user_tz":-540},"id":"3cn7ReSLI8KI"},"outputs":[],"source":["from copy import deepcopy\n","from IPython.display import display, HTML\n","import math\n","from math import sin, cos\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import matplotlib.animation as animation\n","import numpy as np\n","from numpy.random import rand\n","import pickle\n","import time\n","from tqdm import tqdm\n","\n","PI = math.pi\n","\n","class ThrowingEnvironmentBase():\n","    def __init__(self, student_id, q_size):\n","\n","        # Kinematic / Dynamic parameters\n","        self.bound = [(-PI/2, PI/2), (-PI/2, PI/2), (-3*PI, 3*PI), (-3*PI, 3*PI)] # lower/upper bounds for theta1, theta2, omega1, omega2\n","        self.length = [1.0, 1.0] # L1, L2\n","        self.gravity = 9.8\n","        self.trashcan_position = [6.0, -4.0]\n","        self.trashcan_height = 2.0\n","        self.trashcan_radius = 3\n","        self.robot_mass = [1.0, 1.0]\n","        self.trash_mass =  0.5\n","        self.trash_color = 'lightgray'\n","        self.torque = 10.0\n","        self.dt = 0.01\n","        self.action_list = [[1,1,0],[1,-1,0],[-1,1,0],[-1,-1,0],[1,1,1],[1,-1,1],[-1,1,1],[-1,-1,1]]\n","                            # upper arm, lower arm, holding trash = 0 / released = 1\n","\n","        # Reinforcement Learning parameters\n","        self.alpha = 0.1\n","        self.gamma = 0.99\n","        self.epsilon = 0.1\n","\n","        self.fail_reward = -100.0\n","        self.success_reward = 1000.0\n","        self.reward_per_step = 0\n","\n","        self.state = [0.0, 0.0, 0.0, 0.0] # theta1, theta2, omega1, omega2\n","        self.trash_state = [0.0, -2.0, 0.0, 0.0] # x, y, vx, vy\n","        self.is_released = 0 # 1 : released\n","        self.terminal = 0 # 1 : terminate\n","\n","        # Class information\n","        self.epoch = 0\n","        self.step = 0\n","        self.step_limit = 500\n","        self.step_per_epoch = []\n","        self.q_max_per_epoch = []\n","        self.q_avg_per_epoch = []\n","        self.success_number = 0\n","\n","        # Input information\n","        self.q_size = q_size\n","        self.q_table = np.zeros(q_size + [8])\n","        self.student_id = student_id\n","        self.seed = int(student_id.split('-')[1])\n","        np.random.seed(self.seed)\n","        print(\"Environment Initialized\")\n","\n","    def state_mod(self): # function to make thetas in the range of (-PI, PI)\n","        for i in range(2):\n","            n = int(self.state[i] / (2 * PI))\n","            self.state[i] -= n * (2 * PI)\n","            if self.state[i] > PI:\n","                self.state[i] -= 2 * PI\n","            if self.state[i] < - PI:\n","                self.state[i] += 2 * PI\n","            if self.state[i] > PI:\n","                self.state[i] -= 2 * PI\n","            if self.state[i] < - PI:\n","                self.state[i] += 2 * PI\n","\n","    def end_position(self): # end-effector position\n","        t = self.state[0:2]\n","        l = self.length\n","        return [sin(t[0])*l[0]+sin(t[0] + t[1])*l[1], -cos(t[0])*l[0]-cos(t[0] + t[1])*l[1]]\n","\n","    def end_velocity(self): # end-effector velocity\n","        t = self.state[0:2]\n","        w = self.state[2:4]\n","        l = self.length\n","        return [l[0]*cos(t[0])*w[0]+l[1]*cos(t[0]+t[1])*(w[0]+w[1]), l[0]*sin(t[0])*w[0]+l[1]*sin(t[0]+t[1])*(w[0]+w[1])]\n","\n","    def reset(self, fixed_state = None): # restart simulation / training\n","        self.state = [(rand()-0.5)*(self.bound[0][1]-self.bound[0][0])/3, (rand()-0.5)*(self.bound[1][1]-self.bound[1][0])/3, 0, 0]\n","        if fixed_state is not None:\n","            self.state = fixed_state\n","        self.trash_state = deepcopy(self.end_position()+self.end_velocity())\n","        self.is_released = 0\n","        self.terminal = 0\n","        self.step = 0\n","        self.trash_color = 'lightgray'\n","\n","    def action_sample_idx(self): # sample random action index\n","        pass\n","\n","    def epsilon_greedy_action_idx(self, state_idx): # epsilon greedy action, TODO\n","        pass\n","\n","    def discretize(self, state): # make continuous state to discrete state, and return its index\n","        idx = np.zeros_like(state, dtype=int)\n","        for i in range(len(state)):\n","            idx[i] = min(max(math.floor((state[i]-self.bound[i][0]) / (self.bound[i][1]-self.bound[i][0]) * self.q_size[i]),0), self.q_size[i]-1)\n","        return tuple(idx)\n","\n","    def derivs(self, action): # dynamics of robot arm and trash\n","        dydx = np.zeros_like(self.state)\n","        M1, M2 = self.robot_mass[0], self.robot_mass[1]\n","        M = self.trash_mass\n","        if self.is_released:\n","            M = 0\n","        L1, L2 = self.length\n","        G = self.gravity\n","        theta1, theta2 = self.state[0], self.state[0] + self.state[1]\n","        omega1, omega2 = self.state[2], self.state[2] + self.state[3]\n","        dydx[0] = omega1\n","        dydx[1] = omega2\n","        delta = theta2 - theta1\n","        den1 = (M+M1+M2) * L1 - (M+M2) * L1 * cos(delta) * cos(delta)\n","        dydx[2] = (((M+M2) * L1 * omega1 * omega1 * sin(delta) * cos(delta)\n","                    + (M+M2) * G * sin(theta2) * cos(delta)\n","                    + (M+M2) * L2 * omega2 * omega2 * sin(delta)\n","                    - (M+M1+M2) * G * sin(theta1))\n","                / den1)\n","        den2 = (L2/L1) * den1\n","        dydx[3] = ((- (M+M2) * L2 * omega2 * omega2 * sin(delta) * cos(delta)\n","                    + (M+M1+M2) * G * sin(theta1) * cos(delta)\n","                    - (M+M1+M2) * L1 * omega1 * omega1 * sin(delta)\n","                    - (M+M1+M2) * G * sin(theta2))\n","                / den2)\n","        dydx[1] -= dydx[0]\n","        dydx[3] -= dydx[2]\n","        dydx[2] += self.torque * action[0]\n","        dydx[3] += self.torque * action[1]\n","        return dydx\n","\n","    def next_state(self, action): # find (next_state, instant reward, whether the trash has been released or not, whether the simulation should be terminated or not) using current state and input action\n","        assert len(action)==3, \"action space dim should be 3\"\n","        new_state = self.state + self.derivs(action) * self.dt\n","        self.state = new_state\n","        self.state_mod()\n","        if not self.is_released:\n","            self.trash_state = deepcopy(self.end_position()+self.end_velocity())\n","        self.is_released = self.is_released + action[2]\n","        token = 0\n","        for i in range(len(self.state)):\n","            if self.state[i]<self.bound[i][0] or self.state[i]>self.bound[i][1]:\n","                token = i\n","                break\n","        if token or self.is_released or self.step > self.step_limit:\n","            self.terminal = 1\n","        return self.state, deepcopy(self.reward()), self.is_released, self.terminal\n","\n","    def reward(self): # reward for current state and action\n","        if not self.is_released:\n","            if self.terminal:\n","                return self.fail_reward\n","            return self.reward_per_step\n","\n","        trashcan_upperleft = [self.trashcan_position[0]-self.trashcan_radius, self.trashcan_position[1]+self.trashcan_height]\n","        trashcan_upperright = [self.trashcan_position[0]+self.trashcan_radius, self.trashcan_position[1]+self.trashcan_height]\n","        trash_position = self.trash_state[0:2]\n","        trash_velocity = self.trash_state[2:4]\n","        if trash_velocity[0] <= 0:\n","            return self.fail_reward\n","        time_l = (trashcan_upperleft[0] - trash_position[0]) / trash_velocity[0]\n","        trash_left = trash_position[1] + trash_velocity[1] * time_l - 1/2 * self.gravity * time_l ** 2\n","        if trash_left < trashcan_upperleft[1]:\n","            return self.fail_reward\n","        time_r = (trashcan_upperright[0] - trash_position[0]) / trash_velocity[0]\n","        trash_right = trash_position[1] + trash_velocity[1] * time_r - 1/2 * self.gravity * time_r ** 2\n","        if trash_right > trashcan_upperright[1]:\n","            return self.fail_reward\n","        time_inside = (trash_velocity[1] + math.sqrt(trash_velocity[1]**2 - 2 * self.gravity * (trashcan_upperleft[1]-trash_position[1]))) / self.gravity\n","        reward_inside = self.success_reward * (2 - abs(time_inside * trash_velocity[0] + trash_position[0] - self.trashcan_position[0]) / self.trashcan_radius)\n","        return reward_inside\n","\n","    def train_step(self): # train one step, TODO\n","        pass\n","\n","    def train(self, train_n): # training\n","        for _ in tqdm(range(train_n)):\n","            self.reset()\n","            self.epoch += 1\n","            while not self.is_released:\n","                terminal = self.train_step()\n","                if terminal:\n","                    break\n","            self.step_per_epoch.append(self.step)\n","            self.q_max_per_epoch.append(np.max(self.q_table))\n","            self.q_avg_per_epoch.append(np.average(self.q_table))\n","            if self.reward()>0:\n","                self.success_number += 1\n","\n","    def visualization_step(self): # visualize one step\n","        self.step += 1\n","        state_idx = self.discretize(self.state)\n","        A = self.q_table[state_idx]\n","        action = self.action_list[np.random.choice(np.where(A == A.max())[0])]\n","        if not self.is_released:\n","            _, _, _, _ = self.next_state(action)\n","\n","        return self.terminal, deepcopy(self.reward())\n","\n","    def visualization(self): # visualize, when released or terminated - the robot stops; when released - the trash moves in projectile motion\n","        if (not self.is_released) and (self.terminal):\n","            return self.terminal, deepcopy(self.reward())\n","\n","        terminal, reward, = self.visualization_step()\n","        if self.is_released:\n","            if ((self.trash_state[0] >= (self.trashcan_position[0] - self.trashcan_radius)) and ((self.trashcan_position[0] + self.trashcan_radius) >=self.trash_state[0]) and \\\n","                (self.trash_state[1]>=self.trashcan_position[1]) and ((self.trashcan_position[1] + self.trashcan_height) >= self.trash_state[1])):\n","                previous_velocity_x = self.trash_state[2]\n","                previous_velocity_y = self.trash_state[3] + self.gravity * self.dt\n","                previous_position_x = self.trash_state[0] - previous_velocity_x * self.dt\n","                previous_position_y = self.trash_state[1] - previous_velocity_y * self.dt + 1/2 * self.gravity * self.dt **2\n","                left_height = (previous_position_y - self.trash_state[1]) / (previous_position_x - self.trash_state[0]) * \\\n","                                (self.trashcan_position[0] - self.trashcan_radius - self.trash_state[0]) + self.trash_state[1]\n","                if left_height < self.trashcan_position[1] + self.trashcan_height:\n","                    self.trash_state[2] = - self.trash_state[2]\n","                else:\n","                    self.trash_color = 'green'\n","\n","            if (self.trash_color == 'lightgray'):\n","                self.trash_state[0] += self.dt * self.trash_state[2]\n","                self.trash_state[1] += self.dt * self.trash_state[3] - 1/2 * self.gravity * self.dt ** 2\n","                self.trash_state[3] += - self.gravity * self.dt\n","\n","        return terminal, reward\n","\n","    def summary(self): # training information\n","        fig = plt.figure(figsize=(10,12))\n","        ax1 = fig.add_subplot(311)\n","        ax1.plot(self.step_per_epoch)\n","        ax1.set_title(\"step per epoch\")\n","        ax2 = fig.add_subplot(312)\n","        ax2.plot(self.q_max_per_epoch)\n","        ax2.set_title(\"Q_max per epoch\")\n","        ax3 = fig.add_subplot(313)\n","        ax3.plot(self.q_avg_per_epoch)\n","        ax3.set_title(\"Q_avg per epoch\")\n","        print(\"success rate : \",str(self.success_number),\"/\",str(self.epoch))\n","\n","    def plot_state(self): # plot current state\n","        fig = plt.figure(figsize=(7,5))\n","        ax = fig.add_subplot(111)\n","        ax.set_xlabel('X')\n","        ax.set_ylabel('Y')\n","        ax.axis('equal')\n","        ax.axis([-3, 11, -5, 5])\n","\n","        x = [0, sin(self.state[0])*self.length[0], sin(self.state[0])*self.length[0]+sin(self.state[0] + self.state[1])*self.length[1]]\n","        y = [0, -cos(self.state[0])*self.length[0], -cos(self.state[0])*self.length[0]-cos(self.state[0] + self.state[1])*self.length[1]]\n","        ax.plot(x, y, color = 'b', linewidth = 5)\n","        ax.add_patch(plt.Circle((self.trash_state[0],self.trash_state[1]),0.2,edgecolor = 'deeppink', facecolor = 'lightgray', fill = True))\n","        trashcan_x = [self.trashcan_position[0]-self.trashcan_radius, self.trashcan_position[0]-self.trashcan_radius,\n","                        self.trashcan_position[0]+self.trashcan_radius, self.trashcan_position[0]+self.trashcan_radius]\n","        trashcan_y = [self.trashcan_position[1]+self.trashcan_height, self.trashcan_position[1],\n","                        self.trashcan_position[1], self.trashcan_position[1]+self.trashcan_height]\n","        ax.plot(trashcan_x, trashcan_y, color = 'r', linewidth = 5)\n","        ax.text(0.05, 0.9, 'Current State', transform = ax.transAxes)\n","\n","        plt.show()\n","\n","    def plot_simulate(self, duration, reset = True, is_display = True, save_mp4 = True, save_name = 'simulation'): \n","        if reset:\n","            self.reset()\n","        saved_state = self.state\n","\n","        fig = plt.figure(figsize=(7,5))\n","        ax = fig.add_subplot(autoscale_on=False, xlim=(-3, 11), ylim=(-5, 5))\n","        ax.set_xlabel('X')\n","        ax.set_ylabel('Y')\n","        ax.set_aspect('equal')\n","\n","        def animate(i):\n","            plt.cla()\n","            terminal, reward = self.visualization()\n","            ax.set_xlabel('X')\n","            ax.set_ylabel('Y')\n","            ax.axis('equal')\n","            ax.axis([-3, 11, -5, 5])\n","            # print(self.state)\n","            x = [0, sin(self.state[0])*self.length[0], sin(self.state[0])*self.length[0]+sin(self.state[0] + self.state[1])*self.length[1]]\n","            y = [0, -cos(self.state[0])*self.length[0], -cos(self.state[0])*self.length[0]-cos(self.state[0] + self.state[1])*self.length[1]]\n","            ax.plot(x, y, color = 'b', linewidth = 5)\n","            ax.add_patch(plt.Circle((self.trash_state[0],self.trash_state[1]),0.2,edgecolor = 'green', facecolor = self.trash_color, fill = True))\n","            trashcan_x = [self.trashcan_position[0]-self.trashcan_radius, self.trashcan_position[0]-self.trashcan_radius,\n","                          self.trashcan_position[0]+self.trashcan_radius, self.trashcan_position[0]+self.trashcan_radius]\n","            trashcan_y = [self.trashcan_position[1]+self.trashcan_height, self.trashcan_position[1],\n","                          self.trashcan_position[1], self.trashcan_position[1]+self.trashcan_height]\n","            ax.plot(trashcan_x, trashcan_y, color = 'r', linewidth = 5)\n","            if self.is_released:\n","                ax.text(0.05, 0.9, 'time = %.1fs, released'%(i*self.dt),transform = ax.transAxes)\n","            elif terminal:\n","                ax.text(0.05, 0.9, 'time = %.1fs, terminated'%(i*self.dt),transform = ax.transAxes)\n","            else:\n","                ax.text(0.05, 0.9, 'time = %.1fs'%(i*self.dt),transform = ax.transAxes)\n","            if reward > 0:\n","                ax.text(0.05, 0.05, 'success', transform = ax.transAxes)\n","\n","            return fig,\n","\n","        if is_display:\n","            self.reset()\n","            self.state = saved_state\n","            ani = animation.FuncAnimation(fig, animate, repeat_delay = 500,\n","                                        frames=int(duration/self.dt), interval=self.dt * 1000, blit=True)\n","            display(HTML(ani.to_jshtml()))\n","\n","        if save_mp4:\n","            self.reset()\n","            self.state = saved_state\n","            ani2 = animation.FuncAnimation(fig, animate, repeat_delay = 500,\n","                                            frames=int(duration/self.dt), interval=self.dt * 1000, blit=True)\n","            ani2.save('RL_'+save_name+'.mp4')\n","\n","    def load_model(self, filename): # load your model using .pkl\n","        with open(filename, 'rb') as f:\n","            data = pickle.load(f)\n","            self.q_table = data[0]\n","            self.step_per_epoch = data[1]\n","            self.q_max_per_epoch = data[2]\n","            self.q_avg_per_epoch = data[3]\n","            self.success_number = data[4]\n","            self.epoch = data[5]\n","            self.student_id = data[6]\n","\n","    def save_model(self, filename): # save your model using .pkl\n","        Q_TABLE = self.q_table\n","        STEP_PER_EPOCH = self.step_per_epoch\n","        Q_MAX_PER_EPOCH = self.q_max_per_epoch\n","        Q_AVG_PER_EPOCH = self.q_avg_per_epoch\n","        SUCCESS_NUMBER = self.success_number\n","        EPOCH = self.epoch\n","        STUDENT_ID = self.student_id\n","        OBJECTS = [Q_TABLE, STEP_PER_EPOCH, Q_MAX_PER_EPOCH, Q_AVG_PER_EPOCH, SUCCESS_NUMBER, EPOCH, STUDENT_ID]\n","        with open(filename, 'wb') as f:\n","            pickle.dump(OBJECTS, f, pickle.HIGHEST_PROTOCOL)\n","\n","    def submit(self): # create your submit file\n","        filename = self.student_id + '.pkl'\n","        self.save_model(filename)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":483},"executionInfo":{"elapsed":496,"status":"ok","timestamp":1686980973209,"user":{"displayName":"ANKEM HEMA SRIKAR / 학생 / 항공우주공학과 ­","userId":"08215093842889631142"},"user_tz":-540},"id":"7hgHngxvI8KN","outputId":"40c92bbe-1674-4e4a-eac7-ed9e2f44e3d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Environment Initialized\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 700x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["class ThrowingEnvironment(ThrowingEnvironmentBase):\n","    def __init__(self, student_id=\"0000-00000\", q_size=[10, 10, 10, 10]):\n","        super().__init__(student_id=student_id, q_size=q_size)\n","\n","        # Reinforcement Learning parameters\n","        self.alpha = 0.1\n","        self.gamma = 0.99\n","        self.epsilon = 0.1\n","\n","    def action_sample_idx(self):\n","        # sample random action index\n","        action_idx = np.random.randint(len(self.action_list))\n","        return action_idx\n","\n","    def epsilon_greedy_action_idx(self, state_idx):\n","       \n","        if np.random.rand() < self.epsilon:\n","            action_idx = self.action_sample_idx()  # sample random action index\n","        else:\n","            # Choose the action with the highest Q-value for the current state\n","            action_idx = np.argmax(self.q_table[state_idx])\n","\n","        return action_idx\n","\n","    def train_step(self):\n","        \n","        self.step += 1\n","        state_idx = self.discretize(self.state)\n","        action_idx = self.epsilon_greedy_action_idx(state_idx)\n","        action = self.action_list[action_idx]\n","        next_state, reward, _, terminal = self.next_state(action)\n","        next_state_idx = self.discretize(next_state)\n","        if action[2] == 1:  # When the trash is released\n","            self.q_table[state_idx][action_idx] = reward\n","        else:\n","            # Update Q-value using the Q-learning update rule\n","            self.q_table[state_idx][action_idx] += self.alpha * (\n","                reward + self.gamma * np.max(self.q_table[next_state_idx]) - self.q_table[state_idx][action_idx]\n","            )\n","        return terminal\n","\n","discretize = [10, 10, 10, 10]\n","MODEL = ThrowingEnvironment(student_id, q_size=discretize)\n","MODEL.plot_state()"]},{"cell_type":"markdown","metadata":{"id":"fUZ40i6K1p0D"},"source":["#Now, let's train the model."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":731773,"status":"ok","timestamp":1686983353882,"user":{"displayName":"ANKEM HEMA SRIKAR / 학생 / 항공우주공학과 ­","userId":"08215093842889631142"},"user_tz":-540},"id":"ZaI5n8nzI8KO"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000000/1000000 [39:31<00:00, 421.63it/s]\n"]}],"source":["# train the model\n","train_steps = 1000000\n","MODEL.train(train_steps)\n","time.sleep(0.2)\n","\n","# save the model\n","MODEL.submit()"]},{"cell_type":"markdown","metadata":{"id":"9pC23TNo12x6"},"source":["#Let's check if the model has been trained well."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2XiaaDkZI8KO"},"outputs":[],"source":["# test your trained model\n","MODEL.reset([-PI/12, PI/6, 0, 0])\n","MODEL.plot_simulate(5, reset = False, is_display=True, save_mp4=True, save_name='simulation')"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
